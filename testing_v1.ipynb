{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9c69a01",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'genai' from 'google' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m genai\n\u001b[32m      3\u001b[39m client = genai.Client(api_key=\u001b[33m\"\u001b[39m\u001b[33mAIzaSyCq41Zav_pvI9a94iB-_OZpxHXxrGBoum0\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m response = client.models.generate_content(\n\u001b[32m      6\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgemini-2.0-flash\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     contents=\u001b[33m\"\u001b[39m\u001b[33mExplain how AI works in a few words\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'genai' from 'google' (unknown location)"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=\"AIzaSyCq41Zav_pvI9a94iB-_OZpxHXxrGBoum0\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=\"Explain how AI works in a few words\",\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9711d88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI uses algorithms to learn from data and make predictions or decisions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyCq41Zav_pvI9a94iB-_OZpxHXxrGBoum0\")\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "response = model.generate_content(\"Explain how AI works in a few words\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2809cce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini: Hello! How can I help you today?\n",
      "\n",
      "Gemini: I am currently running on Google's servers, processing your request and generating a response. In a more general sense, I'm working on understanding your question, accessing and processing information, and formulating an answer that is hopefully helpful and relevant to you. I don't \"do\" things in the human sense, but I am actively using my programming and knowledge to assist you.\n",
      "\n",
      "Gemini: Okay, let me try to explain it in simpler terms.\n",
      "\n",
      "Imagine I'm like a really fast and knowledgeable librarian. You ask me a question, and I:\n",
      "\n",
      "1. **Read your question:** I analyze what you're asking me.\n",
      "2. **Search for information:** I use my vast database of information (that I've been trained on) to find things related to your question.\n",
      "3. **Put the information together:** I take the information I've found and organize it into a coherent answer.\n",
      "4. **Give you the answer:** I send you the answer in a way you can understand.\n",
      "\n",
      "I'm not a person, so I don't *feel* or *think* in the way humans do. I'm a computer program designed to process information and respond to your requests.\n",
      "\n",
      "Does that make more sense?\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid input: 'content' argument must not be empty. Please provide a non-empty value.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_input.lower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mexit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mquit\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m response = \u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGemini:\u001b[39m\u001b[33m\"\u001b[39m, response.text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GDDE\\AI-GDDE\\ai_agent_cn\\venv\\Lib\\site-packages\\google\\generativeai\\generative_models.py:564\u001b[39m, in \u001b[36mChatSession.send_message\u001b[39m\u001b[34m(self, content, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[39m\n\u001b[32m    558\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    559\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnsupported configuration: The `google.generativeai` SDK currently does not support the combination of `stream=True` and `enable_automatic_function_calling=True`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    560\u001b[39m     )\n\u001b[32m    562\u001b[39m tools_lib = \u001b[38;5;28mself\u001b[39m.model._get_tools_lib(tools)\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m content = \u001b[43mcontent_types\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m content.role:\n\u001b[32m    567\u001b[39m     content.role = _USER_ROLE\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GDDE\\AI-GDDE\\ai_agent_cn\\venv\\Lib\\site-packages\\google\\generativeai\\types\\content_types.py:286\u001b[39m, in \u001b[36mto_content\u001b[39m\u001b[34m(content)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_content\u001b[39m(content: ContentType):\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m content:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    287\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mInvalid input: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m\u001b[33m argument must not be empty. Please provide a non-empty value.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    288\u001b[39m         )\n\u001b[32m    290\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, Mapping):\n\u001b[32m    291\u001b[39m         content = _convert_dict(content)\n",
      "\u001b[31mValueError\u001b[39m: Invalid input: 'content' argument must not be empty. Please provide a non-empty value."
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyCq41Zav_pvI9a94iB-_OZpxHXxrGBoum0\")\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "chat = model.start_chat()\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "    response = chat.send_message(user_input)\n",
    "    print(\"Gemini:\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45641ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 16:35:55.624 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:35:55.765 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run d:\\GDDE\\AI-GDDE\\ai_agent_cn\\venv\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-06-13 16:35:55.766 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:35:55.768 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:35:55.768 Session state does not function when running a script without `streamlit run`\n",
      "2025-06-13 16:35:55.769 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:35:55.770 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:35:55.770 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:35:55.771 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:35:55.772 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:35:55.773 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:35:55.773 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:35:55.774 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:35:55.775 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:35:55.776 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:35:55.776 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:35:55.777 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:35:55.777 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:35:55.778 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:35:55.779 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:35:55.780 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# gemini_chat_app.py\n",
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "\n",
    "st.title(\"Gemini Chatbot\")\n",
    "\n",
    "# Configure your API key\n",
    "genai.configure(api_key=\"AIzaSyCq41Zav_pvI9a94iB-_OZpxHXxrGBoum0\")\n",
    "\n",
    "# Initialize chat session in Streamlit session state\n",
    "if \"chat\" not in st.session_state:\n",
    "    model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "    st.session_state.chat = model.start_chat()\n",
    "    st.session_state.history = []\n",
    "\n",
    "user_input = st.text_input(\"You:\", key=\"input\")\n",
    "\n",
    "if st.button(\"Send\") and user_input:\n",
    "    response = st.session_state.chat.send_message(user_input)\n",
    "    st.session_state.history.append((\"You\", user_input))\n",
    "    st.session_state.history.append((\"Gemini\", response.text))\n",
    "    st.session_state.input = \"\"  # Clear input\n",
    "\n",
    "# Display chat history\n",
    "for speaker, message in st.session_state.history:\n",
    "    st.markdown(f\"**{speaker}:** {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a4f7e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 16:38:30.563 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:38:30.563 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:38:30.564 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:38:30.565 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:38:30.565 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:38:30.565 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:38:30.565 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:38:30.566 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:38:30.566 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:38:30.567 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:38:30.567 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:38:30.568 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:38:30.568 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:38:30.568 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 16:38:30.568 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "\n",
    "st.title(\"Gemini Chatbot\")\n",
    "\n",
    "# Configure your API key\n",
    "genai.configure(api_key=\"AIzaSyCq41Zav_pvI9a94iB-_OZpxHXxrGBoum0\")\n",
    "\n",
    "# Initialize chat session in Streamlit session state\n",
    "if \"chat\" not in st.session_state:\n",
    "    model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "    st.session_state.chat = model.start_chat()\n",
    "    st.session_state.history = []\n",
    "\n",
    "user_input = st.text_input(\"You:\", key=\"input\")\n",
    "\n",
    "if st.button(\"Send\") and user_input:\n",
    "    response = st.session_state.chat.send_message(user_input)\n",
    "    st.session_state.history.append((\"You\", user_input))\n",
    "    st.session_state.history.append((\"Gemini\", response.text))\n",
    "    st.session_state.input = \"\"  # Clear input\n",
    "\n",
    "# Display chat history\n",
    "for speaker, message in st.session_state.history:\n",
    "    st.markdown(f\"**{speaker}:** {message}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
